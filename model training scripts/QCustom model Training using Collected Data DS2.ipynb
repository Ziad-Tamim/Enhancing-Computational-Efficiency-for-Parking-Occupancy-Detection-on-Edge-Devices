{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QCustom model Training using Collected Data DS2\n",
    "Date: 2024-07-15\n",
    "\n",
    "Author: Ziad Tamim\n",
    "\n",
    "Discription:\n",
    "Thsi Script includes the training of the QCustom model. This includes model structure, Quantisation and knowledge disilation.  \n",
    "\n",
    "Inputs:\n",
    "* Dataset\n",
    "\n",
    "Outputs:\n",
    "* Custom model (with no quanisation)\n",
    "* QCustom model (quanized Custom model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check python version\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import keras as k\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# print python version\n",
    "print(f'Python version: ', sys.version)\n",
    "print(f'Tensorflow version: ', tf.__version__)\n",
    "print(f'keras version: ', k.__version__)\n",
    "\n",
    "# Paths to the directories with images\n",
    "occupied_dir = 'C:/Users/ziadt/Desktop/Projects/MSc Project implimintation/Datasets/My Dataset/Occupied'\n",
    "empty_dir = 'C:/Users/ziadt/Desktop/Projects/MSc Project implimintation/Datasets/My Dataset/Empty'\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "# Load images\n",
    "occupied_images = load_images_from_folder(occupied_dir)\n",
    "empty_images = load_images_from_folder(empty_dir)\n",
    "\n",
    "# Prting the number of images in each class\n",
    "print('Loaded', len(occupied_images), 'occupied images')\n",
    "print('Loaded', len(empty_images), 'empty images')\n",
    "\n",
    "\n",
    "def augment_images(images, rotations=[90, 180, 270]):\n",
    "    '''\n",
    "    Augment the images by rotating them by the specified angles.\n",
    "    :param images: list of images in the form of numpy arrays with shape (H, W, C)\n",
    "    :param rotations: list of angles in degrees\n",
    "    :return: list of augmented images\n",
    "    '''\n",
    "    augmented_images = []\n",
    "    for img in images:\n",
    "        original_img = img\n",
    "        augmented_images.append(original_img)  # add the original image\n",
    "        for angle in rotations:\n",
    "            (h, w) = img.shape[:2]\n",
    "            center = (w // 2, h // 2)\n",
    "            M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "            rotated_img = cv2.warpAffine(img, M, (w, h))\n",
    "            augmented_images.append(rotated_img)\n",
    "    return augmented_images\n",
    "\n",
    "def augment_images_flip(images):\n",
    "    augmented_images = []\n",
    "    for img in images:\n",
    "        original_img = img\n",
    "        augmented_images.append(original_img)  # add the original image\n",
    "        flipped_img = cv2.flip(img, 1)\n",
    "        augmented_images.append(flipped_img)\n",
    "    return augmented_images\n",
    "\n",
    "# shuffle the images\n",
    "np.random.shuffle(occupied_images)\n",
    "np.random.shuffle(empty_images)\n",
    "\n",
    "# Augment data\n",
    "occupied_augmented = augment_images(occupied_images)\n",
    "occupied_augmented = augment_images_flip(occupied_augmented)\n",
    "empty_augmented = augment_images(empty_images)\n",
    "\n",
    "# print the number of augmented images\n",
    "print('Number of augmented occupied images:', len(occupied_augmented))\n",
    "print('Number of augmented empty images:', len(empty_augmented))\n",
    "\n",
    "# resize images to 32x32\n",
    "occupied_resized = [cv2.resize(img, (150, 150)) for img in occupied_augmented]\n",
    "empty_resized = [cv2.resize(img, (150, 150)) for img in empty_augmented]\n",
    "\n",
    "# shuffle the images\n",
    "np.random.shuffle(occupied_augmented)\n",
    "np.random.shuffle(empty_augmented)\n",
    "\n",
    "# even the number of images\n",
    "min_len = min(len(occupied_resized), len(empty_resized))\n",
    "occupied_augmented = occupied_resized[:min_len]\n",
    "empty_augmented = empty_resized[:min_len]\n",
    "\n",
    "#print the number of images\n",
    "print('Number of augmented occupied images:', len(occupied_augmented))\n",
    "print('Number of augmented empty images:', len(empty_augmented))\n",
    "\n",
    "# Combine datasets and labels\n",
    "all_images = np.array(occupied_augmented + empty_augmented)\n",
    "labels = np.array([1] * len(occupied_augmented) + [0] * len(empty_augmented))  # 1 for occupied, 0 for empty\n",
    "\n",
    "print('Shape of all images:', all_images.shape)\n",
    "print('Shape of labels:', labels.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training (85%), testing (10%), and validation (5%)\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(all_images, labels, test_size=0.15, random_state=42)\n",
    "test_images, val_images, test_labels, val_labels = train_test_split(test_images, test_labels, test_size=(1/3), random_state=42)  # Approx 10% test, 5% val\n",
    "\n",
    "# Your data is now ready to be used for training, testing, and validation\n",
    "print(f'Train size: {len(train_images)}, Test size: {len(test_images)}, Validation size: {len(val_images)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Custom model structure (Student model)\n",
    "### Discription\n",
    "This code defines the Custom model (Student) use in a knowledge distillation process. The model is intended to be trained by learning from a pre-trained \"teacher\" model. The student model takes 150x150x3 input images and passes them through a series of layers, including initial convolutional layers, multiple MobileNet blocks, and a global average pooling layer. The final output layer uses a sigmoid activation function to produce a single probability score for binary classification (Occupied or Free). The model's compact architecture makes it suitable for distillation, where it will be trained to mimic the behavior of a more complex teacher model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, DepthwiseConv2D, Conv2D, BatchNormalization\n",
    "from tensorflow.keras.layers import ReLU, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "\n",
    "# MobileNet block\n",
    "def mobilnet_block(x, filters, strides): # this function is used to create a mobilenet block consisting of depthwise convolution followed by pointwise convolution\n",
    "    x = DepthwiseConv2D(kernel_size=3, strides=strides, padding='same')(x) # depthwise convolution\n",
    "    x = BatchNormalization()(x) \n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    x = Conv2D(filters=filters, kernel_size=1, strides=1)(x) # pointwise convolution\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    return x # return the output of the block\n",
    "\n",
    "# Input specification for the model\n",
    "input = Input(shape=(150, 150, 3))  # image input size is 150x150x3\n",
    "x = Conv2D(filters=16, kernel_size=3, strides=2, padding='same')(input) # first layer conv2d\n",
    "x = BatchNormalization()(x) # first layer batch normalization\n",
    "x = ReLU()(x) # first layer ReLU\n",
    "\n",
    "# Main part of the model\n",
    "x = mobilnet_block(x, filters=5, strides=1) # second layer mobilenet block\n",
    "x = mobilnet_block(x, filters=5, strides=2) # third layer mobilenet block\n",
    "x = mobilnet_block(x, filters=12, strides=1) # fourth layer mobilenet block\n",
    "x = mobilnet_block(x, filters=12, strides=2) # fifth layer mobilenet block\n",
    "x = mobilnet_block(x, filters=24, strides=1) # sixth layer mobilenet block\n",
    "x = mobilnet_block(x, filters=24, strides=2) # seventh layer mobilenet block\n",
    "x = mobilnet_block(x, filters=24, strides=2) # eighth layer mobilenet block\n",
    "\n",
    "# Adjusting for binary classification\n",
    "x = GlobalAveragePooling2D()(x)  # Changed from AvgPool2D to GlobalAveragePooling2D\n",
    "output = Dense(units=1, activation='sigmoid')(x)  # Changed to one unit with sigmoid activation\n",
    "\n",
    "# Create the model\n",
    "student = Model(inputs=input, outputs=output) # create the model \n",
    "student.summary()\n",
    "student.input_shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet50 model (Teacher model)\n",
    "This code sets up the teacher model for knowledge distillation using a pre-trained ResNet50 architecture. The ResNet50 model's layers are frozen to retain the pre-trained ImageNet weights. A global average pooling layer and a sigmoid-activated dense layer are added on top to adapt the model for binary classification. This model will serve as the teacher in the knowledge distillation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on resnet\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "# load the model\n",
    "resnet = ResNet50(include_top=False, weights='imagenet', input_shape=(150, 150, 3))\n",
    "resnet.summary()\n",
    "\n",
    "# Freeze the layers\n",
    "for layer in resnet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add the top layers\n",
    "x = resnet.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "teacher = Model(resnet.input, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distillation Model Setup\n",
    "This code defines the Distiller class, a custom TensorFlow model designed to facilitate knowledge distillation. The class combines a teacher and student model, allowing the student to learn from both the true labels and the teacher's predictions. The distillation process is controlled by parameters like alpha (balancing student and distillation loss) and temperature (smoothing the teacher's predictions). The Distiller is then instantiated, compiled with binary cross-entropy for the student loss, and Kullback-Leibler divergence for the distillation loss, and is ready for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Distiller(tf.keras.Model): # this class is used to create a distiller model that will be used to train the student model\n",
    "    def __init__(self, student, teacher):\n",
    "        super(Distiller, self).__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "\n",
    "    def compile( # this function is used to compile the model\n",
    "        self,\n",
    "        optimizer,\n",
    "        metrics,\n",
    "        student_loss_fn,\n",
    "        distillation_loss_fn,\n",
    "        alpha=0.1, # alpha is the weight given to the student loss\n",
    "        temperature=3, # temperature is used to soften the predictions\n",
    "    ):\n",
    "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics) # compile the model with the optimizer and metrics\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def train_step(self, data): # this function is used to train the model using the distillation loss\n",
    "        x, y = data\n",
    "        teacher_predictions = self.teacher(x, training=False)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            student_predictions = self.student(x, training=True)\n",
    "            student_loss = self.student_loss_fn(y, student_predictions)\n",
    "            distillation_loss = self.distillation_loss_fn(\n",
    "                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
    "                tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
    "            )\n",
    "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss # calculate the loss using the distillation loss\n",
    "\n",
    "        gradients = tape.gradient(loss, self.student.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.student.trainable_variables))\n",
    "        self.compiled_metrics.update_state(y, student_predictions)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update({\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}) # update the results with the student loss and distillation loss\n",
    "        return results\n",
    "\n",
    "    #Test 2\n",
    "    def test_step(self, data): # this function is used to test the model using the distillation loss\n",
    "        x, y = data\n",
    "        student_predictions = self(x, training=False)\n",
    "        student_loss = self.student_loss_fn(y, student_predictions)\n",
    "\n",
    "        # Update metrics\n",
    "        self.compiled_metrics.update_state(y, student_predictions)\n",
    "\n",
    "        # Collect metrics results\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results['loss'] = student_loss\n",
    "        return results\n",
    "\n",
    "    def call(self, inputs, training=False): # this function is used to call the model\n",
    "        if training:\n",
    "            return self.student(inputs, training=True)\n",
    "        else:\n",
    "            return self.student(inputs, training=False)\n",
    "\n",
    "# Create the distiller instance again and compile it\n",
    "distiller = Distiller(student=student, teacher=teacher)\n",
    "distiller.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
    "    student_loss_fn=tf.keras.losses.BinaryCrossentropy(),\n",
    "    distillation_loss_fn=tf.keras.losses.KLDivergence(),\n",
    "    alpha=0.1,\n",
    "    temperature=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard initialization\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "path_to_logs = \"C:/Users/ziadt/Desktop/Projects/MSc Project implimintation/Model Training/CustomeNEt/training supporting material/logs/fit/\"\n",
    "\n",
    "# Create a TensorBoard callback\n",
    "log_dir = path_to_logs + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the distiller\n",
    "distiller.fit(train_images, train_labels, validation_data=(val_images, val_labels), epochs=1, batch_size=32, callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy perfomance on the test set\n",
    "distiller.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Custom model without Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "student.save('C:/Users/ziadt/Desktop/Projects/MSc Project implimintation/Model Training/CustomeNEt/training supporting material/student_model_DS2.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('C:/Users/ziadt/Desktop/Projects/MSc Project implimintation/Model Training/CustomeNEt/training supporting material/student_model_DS2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Training Interger Quantization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full integer quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(distiller.student)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open('QCustom_D2_V1.tflite', 'wb').write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference speed of the QCustom model on a single slot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "\n",
    "# test data\n",
    "image = test_images[0]\n",
    "\n",
    "\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image = cv2.resize(image, (150, 150))\n",
    "image = np.expand_dims(image, axis=0)\n",
    "image = image / 255.0\n",
    "image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "\n",
    "\n",
    "# Test the model on random input data.\n",
    "times = []\n",
    "for i in range(100):\n",
    "    start_time = time.time()\n",
    "    interpreter.set_tensor(input_details[0]['index'], image)\n",
    "    interpreter.invoke()\n",
    "    end_time = time.time()\n",
    "    times.append(end_time - start_time)\n",
    "\n",
    "print('Average inference time for 100 images with quantized model:', np.mean(times))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newvm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
